简介：高性能的分布式内存对象缓存系统。
1。Memcached 特征
    （1）内置内存存储方式：Memcached保存的数据都存储在Memcached内置的内存存储空间中。由于数据仅存在内存中，
因此重启Memcached会导致全部数据消失。另外，内存容量达到指定的值之后，Memcached会自动删除不使用的内存，
数据缓存的回收采用的是LRU算法。
    （2）Memcached客户端分布式：Memcached尽管是分布式缓存服务器，但服务器端并没有分布式功能。各个Memcached
实例不会互相通信以共享信息，他的分布式主要是通过客户端实现的，图如文件：

2。Memcached 的一些问题
    （1）无法备份，重启无法恢复
    （2）无法查询：不能按各种条件的key查询，比如范围查询
    （3）没有提供内置的安全机制
    （4）单点故障failover：Memcached不支持任何故障转移/高可用机制，因为它是作为cache使用的，不是原始数据源。
面对单点故障，可以通过主从模式解决问题，

3。Memcached内存存储：默认情况下采用了 Slab Allocatoion的机制分配、管理内存。
    （1）Slab Allocatoion 机制（以下简称 SA）
在SA机制出现以前，内存的分配是通过对所有记录简单的进行 malloc 和 free 来进行的，但是这种方式会导致内存碎片，
加重操作系统内存管理器的负担。SA的原理是按照预先规定的大小，将分配的内存分割成各种尺寸的块，
并把尺寸相同的块分成组，分配的块可以重复利用，不释放到内存中，
    SA机制简单的来说是，Memcached 根据收到的数据的大小，选择最合适数据大小的块，Memcached中保存这块内空闲内存
的列表，根据该列表选择内存，然后将数据缓存其中，
    SA解决了当初内存碎片问题，但新的机制也给Memcached带来了新的问题，由于分配的是特定长度的内存，因此无法有效利用
    分配的内存，例如：100 bytes的空间使用了 112字节的内存空间，剩余的12字节就浪费了

4。使用Growth factor进行调优
5。典型问题解析：
    Memcached 的内存是有限的，对于大量的或者过期的数据，是如何进行管理的？单实例Memcached的业务场景下，随着业务规模的不断增长
    一般会出现以下几个问题：
    （1）容量问题：
    （2）服务高可用：单实例场景下，缓存如果因为网络波动等原因不可用，会让访问全部穿透到数据库层，这在架构上是致命风险
    （3）扩展问题：单一服务节点无法突破单实例请求峰值上限，比如热点问题，微博的热点事件，淘宝的热点单品秒杀都是此类。
我们要确保高于日常N倍的请求到达，扩展性问题也是分布式方案的基本问题。

6。过期机制
    （1）Lazy Expiration：Memcached内部不会监视记录是否过期，而是在get时查看记录的时间戳，检查记录是否过期。
这种技术被称为惰性过期，因此 Memcached 不会在过期监视上耗费CPU时间
    （2）LRU算法：最近最少使用算法。Memcached启动时通过 "—M" 参数可以禁止LRU memcached -M -m 1024
小写的 -m 是用来指定最大内存大小的，不指定具体值则使用默认值 64MB，指定 —M 参数启动后，内存用尽时，memcached会返回错误

7。哈希算法
    哈希：任意长度的输入，通过散列算法，变成固定长度的输出。为了解决单实例的瓶颈，需要Memcached进行分布式部署，
    分布式部署依赖的核心便是Hash算法，有三个Memcached实例，一般的Hash算法为：hash (key) mod 3,
    将key进行散列计算，再取模便可选择一个固定的Memcached实例，该Hash方案接口简单，但是缺点非常突出。
    假设需要扩容一台Memcached实例，那么该Hash算法便修改为 hash (key) mod 4,这会导致历史所有的数据都无法找到。
    导致大量的访问回源
    在分布式集群中，对机器的添加、删除，或机器故障后自动脱离机器这些操作是分布式集群管理最基本的功能，使用一致性
    Hash可以很好的解决动态变化环境下使用Memcached扩缩容带来的大量数据失效问题

    遗留：一致性Hash算法和普通Hash算法的区别，为什么一致性Hash算法可以解决机器扩容和缩容

8。热点问题：数据访问热点（读热点问题），一旦请求量达到单机极限也会存在热点保护问题。
   热点问题通用的解决思路：当发现热点数据时候，不要请求到集中式缓存，而是直接请求本地缓存 Ehcache等
   巨热数据的处理方式:通过多个key来获取key的数据，其实质就是把key 分散，对于非高一致性要求的高并发读还是蛮有效的

9。缓存和数据库的更新问题
    （1）先更新DB，再删除缓存
    问题：数据DB更新成功，缓存更新失败，结果是缓存中存在旧的数据，用户获取到旧的信息，存在不一致性。

10。别把缓存当存储















